{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6qTVjOCWZeH",
        "outputId": "72661fb0-4161-47e9-eeeb-6d97a0e6add2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pymongo[srv] in /usr/local/lib/python3.7/dist-packages (4.2.0)\n",
            "Collecting dnspython<3.0.0,>=1.16.0\n",
            "  Downloading dnspython-2.2.1-py3-none-any.whl (269 kB)\n",
            "\u001b[K     |████████████████████████████████| 269 kB 30.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: dnspython\n",
            "Successfully installed dnspython-2.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install \"pymongo[srv]\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pymongo import MongoClient\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "client =  MongoClient(\"mongodb+srv://twittersentimentanalysis:Twitter01@cluster0.n2bao.mongodb.net/?retryWrites=true&w=majority\")\n",
        "db = client['twitterSentiment']\n",
        "col = db['clean']"
      ],
      "metadata": {
        "id": "CNutcD1DWucR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.DataFrame(list(col.find()))"
      ],
      "metadata": {
        "id": "ojK7kM9IWxXw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1=pd.DataFrame()\n",
        "df1['TEXT']=df.Tweet_punct"
      ],
      "metadata": {
        "id": "FZOSISGjW0HB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "GlqA6W1AW2qI",
        "outputId": "3def370d-ae5d-4483-9f5c-ce5656926685"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   TEXT\n",
              "0     rt goldseek you can be bullish on bitcoin and ...\n",
              "1     rt orfonline the current ukrainecrisis is dipl...\n",
              "2     rt pcmcindiagovin pcmc covid updates date  til...\n",
              "3     rt ignisfatum ‼️putin regime propaganda agency...\n",
              "4     rt jakewujastyk btc bitcoin continues to hold ...\n",
              "...                                                 ...\n",
              "3941  bitcoin is currently holding above trendline s...\n",
              "3942  rt amirza russia ukraine ukrainerussia \\nthe d...\n",
              "3943  there are more than  of shorts  on binance fut...\n",
              "3944       rt rovercrc bitcoin to  by the end of march \n",
              "3945  rt yenerdemiroglu this price is free now take ...\n",
              "\n",
              "[3946 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-37b64e9a-0fc2-4a0d-8831-5ad01967a831\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TEXT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rt goldseek you can be bullish on bitcoin and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>rt orfonline the current ukrainecrisis is dipl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>rt pcmcindiagovin pcmc covid updates date  til...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>rt ignisfatum ‼️putin regime propaganda agency...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>rt jakewujastyk btc bitcoin continues to hold ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3941</th>\n",
              "      <td>bitcoin is currently holding above trendline s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3942</th>\n",
              "      <td>rt amirza russia ukraine ukrainerussia \\nthe d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3943</th>\n",
              "      <td>there are more than  of shorts  on binance fut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3944</th>\n",
              "      <td>rt rovercrc bitcoin to  by the end of march</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3945</th>\n",
              "      <td>rt yenerdemiroglu this price is free now take ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3946 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37b64e9a-0fc2-4a0d-8831-5ad01967a831')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-37b64e9a-0fc2-4a0d-8831-5ad01967a831 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-37b64e9a-0fc2-4a0d-8831-5ad01967a831');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install clean-text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atd64qL5W4Su",
        "outputId": "a257ba4c-cdda-43e5-bb52-490e622091b7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting clean-text\n",
            "  Downloading clean_text-0.6.0-py3-none-any.whl (11 kB)\n",
            "Collecting ftfy<7.0,>=6.0\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.4 MB/s \n",
            "\u001b[?25hCollecting emoji<2.0.0,>=1.0.0\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[K     |████████████████████████████████| 175 kB 59.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy<7.0,>=6.0->clean-text) (0.2.5)\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171046 sha256=7a0bd90a66ab7ca5db484a14469f2843e46f6e55c958bdef0812dfd649e0fe2c\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/4e/b6/57b01db010d17ef6ea9b40300af725ef3e210cb1acfb7ac8b6\n",
            "Successfully built emoji\n",
            "Installing collected packages: ftfy, emoji, clean-text\n",
            "Successfully installed clean-text-0.6.0 emoji-1.7.0 ftfy-6.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from cleantext import clean\n",
        "clean(df1['TEXT'], no_emoji=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "UECzSd1RW9xy",
        "outputId": "ef1558d6-9ddc-406b-be60-084dc44fa6e4"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0 rt goldseek you can be bullish on bitcoin and ...\\n1 rt orfonline the current ukrainecrisis is dipl...\\n2 rt pcmcindiagovin pcmc covid updates date til...\\n3 rt ignisfatum putin regime propaganda agency...\\n4 rt jakewujastyk btc bitcoin continues to hold ...\\n...\\n3941 bitcoin is currently holding above trendline s...\\n3942 rt amirza russia ukraine ukrainerussia\\nthe d...\\n3943 there are more than of shorts on binance fut...\\n3944 rt rovercrc bitcoin to by the end of march\\n3945 rt yenerdemiroglu this price is free now take ...\\nname: text, length: 3946, dtype: object'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "#text = u'This is a smiley face \\U0001f602'\n",
        "#print(text) # with emoji\n",
        "\n",
        "def deEmojify(text):\n",
        "    regrex_pattern = re.compile(pattern = \"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\u2757\"\n",
        "                           \"]+\", flags = re.UNICODE)\n",
        "    return regrex_pattern.sub(r'',text)\n",
        "df1['deEmojify'] = df1['TEXT'].apply(lambda x:deEmojify(x))\n",
        "#print(deEmojify(text))"
      ],
      "metadata": {
        "id": "pcrV2-gmXAmQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['deEmojify']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgpxMvbTXDz_",
        "outputId": "43f736de-00c7-431c-f1eb-50ee88e03910"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       rt goldseek you can be bullish on bitcoin and ...\n",
              "1       rt orfonline the current ukrainecrisis is dipl...\n",
              "2       rt pcmcindiagovin pcmc covid updates date  til...\n",
              "3       rt ignisfatum ‼️putin regime propaganda agency...\n",
              "4       rt jakewujastyk btc bitcoin continues to hold ...\n",
              "                              ...                        \n",
              "3941    bitcoin is currently holding above trendline s...\n",
              "3942    rt amirza russia ukraine ukrainerussia \\nthe d...\n",
              "3943    there are more than  of shorts  on binance fut...\n",
              "3944         rt rovercrc bitcoin to  by the end of march \n",
              "3945    rt yenerdemiroglu this price is free now take ...\n",
              "Name: deEmojify, Length: 3946, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def removepunct(text):\n",
        "  text=text.replace('[','')\n",
        "  text=text.replace('#','')\n",
        "  text=text.replace(']','')\n",
        "  text=text.replace('(','')\n",
        "  text=text.replace(')','')\n",
        "  text=text.replace('\"','')\n",
        "  text=text.replace(\"'\",'')\n",
        "  text=text.replace(\"!\",'')\n",
        "  text=text.replace(\"!!\",'')\n",
        "  text=text.replace(\"—\",' ')\n",
        "  text=text.replace(\"\\n\",' ')\n",
        "\n",
        "  return text\n",
        "df1['punct_remov'] = df1['deEmojify'].apply(lambda x:removepunct(x))\n",
        "#df1['punct_remov'] = df1['TEXT'].apply(lambda x:str(x).replaceAll(\"[\\\\-\\\\+\\\\.\\\\^:,]\",\"\"))"
      ],
      "metadata": {
        "id": "CZfZWD6FXMpc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.punct_remov[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "OCcKJRV8XPo2",
        "outputId": "4a95bce1-6d5c-4443-c900-538f0fe80b0f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'rt goldseek you can be bullish on bitcoin and bearish on its price  would you not love bitcoin more at '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1['Clean']=df1['punct_remov'].apply(lambda x:x.split(' ', 2))"
      ],
      "metadata": {
        "id": "SCUFvX5vXVpl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['Clean1']=df1['punct_remov'].apply(lambda x:x.split(' ', 2)[2:])"
      ],
      "metadata": {
        "id": "l6t_gku7XYzC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_trf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkpcDgR-Xe0m",
        "outputId": "7b389d48-888d-4ad9-90a7-3c1a1dff5e84"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-trf==3.4.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_trf-3.4.1/en_core_web_trf-3.4.1-py3-none-any.whl (460.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 460.3 MB 28 kB/s \n",
            "\u001b[?25hCollecting spacy-transformers<1.2.0,>=1.1.2\n",
            "  Downloading spacy_transformers-1.1.8-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.1 in /usr/local/lib/python3.7/dist-packages (from en-core-web-trf==3.4.1) (3.4.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (2.0.8)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (3.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (21.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (1.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (8.1.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (2.0.7)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (1.21.6)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (0.6.2)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (4.1.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (3.0.10)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (0.10.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (57.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (2.11.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (2.4.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (1.9.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (2.23.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (4.64.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (1.0.3)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (0.4.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (3.9.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (5.2.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (1.24.3)\n",
            "Collecting spacy-alignments<1.0.0,>=0.7.2\n",
            "  Downloading spacy_alignments-0.8.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 28.2 MB/s \n",
            "\u001b[?25hCollecting transformers<4.22.0,>=3.4.0\n",
            "  Downloading transformers-4.21.3-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 56.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==3.4.1) (1.12.1+cu113)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (0.7.8)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (0.0.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==3.4.1) (4.13.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 71.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==3.4.1) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==3.4.1) (3.8.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->en-core-web-trf==3.4.1) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 74.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.1->en-core-web-trf==3.4.1) (2.0.1)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers, spacy-alignments, spacy-transformers, en-core-web-trf\n",
            "Successfully installed en-core-web-trf-3.4.1 huggingface-hub-0.10.1 spacy-alignments-0.8.6 spacy-transformers-1.1.8 tokenizers-0.12.1 transformers-4.21.3\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_trf')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df1.copy()"
      ],
      "metadata": {
        "id": "_0hEDk91Xjc6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yiy8zPP8Xllh",
        "outputId": "427685d8-faa8-4b62-ef96-81dbb3242b4d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['TEXT', 'deEmojify', 'punct_remov', 'Clean', 'Clean1'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.drop(['TEXT', 'deEmojify', 'punct_remov', 'Clean'], inplace= True, axis =1)"
      ],
      "metadata": {
        "id": "fI-Mt7HfXn8j"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "spacy.load('en_core_web_trf')\n",
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()\n",
        "def label(text):\n",
        "    # for t in text:\n",
        "    eng_doc = nlp(text)\n",
        "    return [(ent.start_char,ent.end_char, str(ent.label_)) for ent in eng_doc.ents]"
      ],
      "metadata": {
        "id": "wSNgb3LWXqYG"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.training import offsets_to_biluo_tags\n",
        "df2['Clean1'] = df2['Clean1'].apply(lambda x: x[0] if len(x) > 0 else '')\n",
        "df2 = df2[df2['Clean1'].apply(lambda x: len(label(x)) > 0)]\n",
        "df2['tagged_text'] = df2['Clean1'].apply(lambda x: ' '.join(offsets_to_biluo_tags(nlp(x), label(x))))"
      ],
      "metadata": {
        "id": "NqqjxJitXtQg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df2.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7Kk0_AdXvqO",
        "outputId": "c53a7053-d884-465a-91c0-1090958dea31"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              Clean1  \\\n",
            "1  the current ukrainecrisis is diplomatically ch...   \n",
            "2  pcmc covid updates date  till  pm for more inf...   \n",
            "3  ‼️putin regime propaganda agency broadcast fro...   \n",
            "4  btc bitcoin continues to hold the support zone...   \n",
            "5  there are unconfirmed news that the russian pa...   \n",
            "\n",
            "                                         tagged_text  \n",
            "1    O O O O O O O B-GPE L-GPE O O O O O O O O O O O  \n",
            "2  B-PERSON L-PERSON O O O O O O O O O O O O O O O O  \n",
            "3  O O O O O O U-DATE O O O O O O O O O O O O O O...  \n",
            "4           B-ORG L-ORG O O O O O O O O O U-DATE O O  \n",
            "5  O O O O O O U-NORP O O O O O O O O O O O O U-G...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df2.index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZChVeqwcXyi1",
        "outputId": "8d8b19dd-c159-44db-eb65-a4ee847d54f6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2405"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5UoUukVZ6Vx",
        "outputId": "ce4bdfcb-56d8-4708-b4bb-639195cb1142"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.21.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.9.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "#change columns names\n",
        "#df2.rename(columns = {'text':'Clean1', 'labels':'tagged_text'}, inplace = True)\n",
        "\n",
        "#split train, dev , test sets\n",
        "df_train, df_dev, df_test = np.split(df2.sample(frac=1, random_state=42),\n",
        "                            [int(.8 * len(df)), int(.9 * len(df))])"
      ],
      "metadata": {
        "id": "HO6lE30ZCgiM"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "KnvDRCQlGgjv",
        "outputId": "186932fa-bbb2-49ff-ae91-0107b600a7ef"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 Clean1  \\\n",
              "3538  amp warpac nato not only provoke ukrainerussia...   \n",
              "2485  website contact forms to spread bazarloader ma...   \n",
              "2253  a number of captured ukrainian armor by dprrus...   \n",
              "3890  dont have any position in bitcoin or eth now y...   \n",
              "1847  downgraded their forecasts for us economic gro...   \n",
              "...                                                 ...   \n",
              "2646  just in russians are liquidating billions in b...   \n",
              "1799  bemil nft metaverse pe bemilgame i would very ...   \n",
              "1852  countries human beings are born free and equal...   \n",
              "2121   israel pm proposed zelenskyy to surrender to ...   \n",
              "1435  russia began massing troops on the ukraine bor...   \n",
              "\n",
              "                                            tagged_text  \n",
              "3538                  O O U-ORG O O O O O O O O O O O O  \n",
              "2485                  O O O O O O O O O O O B-ORG L-ORG  \n",
              "2253             O O O O O O O U-NORP O O O O U-GPE O O  \n",
              "3890  O O O O O O O O O O O O O O O B-DATE I-DATE L-...  \n",
              "1847          O O O O O O O O B-DATE L-DATE O O O O O O  \n",
              "...                                                 ...  \n",
              "2646  O O U-NORP O O U-CARDINAL O O O O O U-GPE O O ...  \n",
              "1799    U-ORG O O O O O O O O O O O O O O O O O O O O O  \n",
              "1852        O O O O O O O O O O O O O O O O O U-GPE O O  \n",
              "2121            O U-GPE O O O O O O U-GPE O O O O O O O  \n",
              "1435  U-GPE O O O O O O O B-DATE I-DATE I-DATE I-DAT...  \n",
              "\n",
              "[2405 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5f0e6bc1-d7cc-4ad4-8424-f54c23de4726\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Clean1</th>\n",
              "      <th>tagged_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3538</th>\n",
              "      <td>amp warpac nato not only provoke ukrainerussia...</td>\n",
              "      <td>O O U-ORG O O O O O O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2485</th>\n",
              "      <td>website contact forms to spread bazarloader ma...</td>\n",
              "      <td>O O O O O O O O O O O B-ORG L-ORG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2253</th>\n",
              "      <td>a number of captured ukrainian armor by dprrus...</td>\n",
              "      <td>O O O O O O O U-NORP O O O O U-GPE O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3890</th>\n",
              "      <td>dont have any position in bitcoin or eth now y...</td>\n",
              "      <td>O O O O O O O O O O O O O O O B-DATE I-DATE L-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1847</th>\n",
              "      <td>downgraded their forecasts for us economic gro...</td>\n",
              "      <td>O O O O O O O O B-DATE L-DATE O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2646</th>\n",
              "      <td>just in russians are liquidating billions in b...</td>\n",
              "      <td>O O U-NORP O O U-CARDINAL O O O O O U-GPE O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1799</th>\n",
              "      <td>bemil nft metaverse pe bemilgame i would very ...</td>\n",
              "      <td>U-ORG O O O O O O O O O O O O O O O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1852</th>\n",
              "      <td>countries human beings are born free and equal...</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O U-GPE O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2121</th>\n",
              "      <td>israel pm proposed zelenskyy to surrender to ...</td>\n",
              "      <td>O U-GPE O O O O O O U-GPE O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1435</th>\n",
              "      <td>russia began massing troops on the ukraine bor...</td>\n",
              "      <td>U-GPE O O O O O O O B-DATE I-DATE I-DATE I-DAT...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2405 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f0e6bc1-d7cc-4ad4-8424-f54c23de4726')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5f0e6bc1-d7cc-4ad4-8424-f54c23de4726 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5f0e6bc1-d7cc-4ad4-8424-f54c23de4726');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install transformers\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "import transformers\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import  DistilBertForTokenClassification\n",
        "\n",
        "from torch.optim import AdamW\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import SGD\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from sklearn.metrics import accuracy_score,f1_score, precision_score, recall_score"
      ],
      "metadata": {
        "id": "3WiwWqQKDf4S"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DistilbertNER(nn.Module):\n",
        "  \"\"\"\n",
        "  Implement NN class based on distilbert pretrained from Hugging face.\n",
        "  Inputs : \n",
        "    tokens_dim : int specifyng the dimension of the classifier\n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self, tokens_dim):\n",
        "    super(DistilbertNER,self).__init__()\n",
        "    \n",
        "    if type(tokens_dim) != int:\n",
        "            raise TypeError('Please tokens_dim should be an integer')\n",
        "\n",
        "    if tokens_dim <= 0:\n",
        "          raise ValueError('Classification layer dimension should be at least 1')\n",
        "\n",
        "    self.pretrained = DistilBertForTokenClassification.from_pretrained(\"distilbert-base-uncased\", num_labels = tokens_dim) #set the output of each token classifier = unique_lables\n",
        "\n",
        "\n",
        "  def forward(self, input_ids, attention_mask, labels = None): #labels are needed in order to compute the loss\n",
        "    \"\"\"\n",
        "  Forwad computation of the network\n",
        "  Input:\n",
        "    - inputs_ids : from model tokenizer\n",
        "    - attention :  mask from model tokenizer\n",
        "    - labels : if given the model is able to return the loss value\n",
        "  \"\"\"\n",
        "\n",
        "    #inference time no labels\n",
        "    if labels == None:\n",
        "      out = self.pretrained(input_ids = input_ids, attention_mask = attention_mask )\n",
        "      return out\n",
        "\n",
        "    out = self.pretrained(input_ids = input_ids, attention_mask = attention_mask , labels = labels)\n",
        "    return out"
      ],
      "metadata": {
        "id": "rN3tluNvCggG"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NerDataset(torch.utils.data.Dataset):\n",
        "  \"\"\"\n",
        "  Custom dataset implementation to get (text,labels) tuples\n",
        "  Inputs:\n",
        "   - df : dataframe with columns [tags, sentence]\n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self, df):\n",
        "    #if not isinstance(df, pd.DataFrame):\n",
        "     # raise TypeError('Input should be a dataframe')\n",
        "    \n",
        "    #if \"tags\" not in df.columns or \"sentence\" not in df.columns:\n",
        "    #  raise ValueError(\"Dataframe should contain 'tags' and 'sentence' columns\")\n",
        "\n",
        "     \n",
        "    \n",
        "    tags_list = [i.split() for i in df2[\"tagged_text\"].values.tolist()]\n",
        "    texts = df2[\"Clean1\"].values.tolist()\n",
        "\n",
        "    self.texts = [tokenizer(text, padding = \"max_length\", truncation = True, return_tensors = \"pt\") for text in texts]\n",
        "    self.labels = [match_tokens_labels(text, tags) for text,tags in zip(self.texts, tags_list)]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.labels)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    batch_text = self.texts[idx]\n",
        "    batch_labels = self.labels[idx]\n",
        "\n",
        "    return batch_text, torch.LongTensor(batch_labels)"
      ],
      "metadata": {
        "id": "yXkd58sYCgdf"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tags_2_labels(tags : str, tag2idx : dict):\n",
        "  '''\n",
        "  Method that takes a list of tags and a dictionary mapping and returns a list of labels (associated).\n",
        "  Used to create the \"label\" column in df from the \"tags\" column.\n",
        "  '''\n",
        "  return [tag2idx[tag] if tag in tag2idx else unseen_label for tag in tags.split()] "
      ],
      "metadata": {
        "id": "0JeHP9sECgag"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MetricsTracking():\n",
        "  \"\"\"\n",
        "  In order make the train loop lighter I define this class to track all the metrics that we are going to measure for our model.\n",
        "\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "\n",
        "    self.total_acc = 0\n",
        "    self.total_f1 = 0\n",
        "    self.total_precision = 0\n",
        "    self.total_recall = 0\n",
        "\n",
        "  def update(self, predictions, labels , ignore_token = -100):\n",
        "    '''\n",
        "    Call this function every time you need to update your metrics.\n",
        "    Where in the train there was a -100, were additional token that we dont want to label, so remove them.\n",
        "    If we flatten the batch its easier to access the indexed = -100\n",
        "\n",
        "    '''  \n",
        "    predictions = predictions.flatten()\n",
        "    labels = labels.flatten()\n",
        "    \n",
        "    predictions = predictions[labels != ignore_token]\n",
        "    labels = labels[labels != ignore_token]\n",
        "\n",
        "    predictions = predictions.to(\"cpu\")\n",
        "    labels = labels.to(\"cpu\")\n",
        "\n",
        "    acc = accuracy_score(labels,predictions)\n",
        "    f1 = f1_score(labels, predictions, average = \"macro\")\n",
        "    precision = precision_score(labels, predictions, average = \"macro\")\n",
        "    recall = recall_score(labels, predictions, average = \"macro\")\n",
        "\n",
        "    self.total_acc  += acc\n",
        "    self.total_f1 += f1\n",
        "    self.total_precision += precision\n",
        "    self.total_recall  += recall\n",
        "\n",
        "  def return_avg_metrics(self,data_loader_size):\n",
        "    n = data_loader_size\n",
        "    metrics = {\n",
        "        \"acc\": round(self.total_acc / n ,3), \n",
        "        \"f1\": round(self.total_f1 / n, 3), \n",
        "        \"precision\" : round(self.total_precision / n, 3), \n",
        "        \"recall\": round(self.total_recall / n, 3)\n",
        "          }\n",
        "    return metrics   "
      ],
      "metadata": {
        "id": "gKvvDDerFrC8"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tags_mapping(tags_series : pd.Series):\n",
        "  \"\"\"\n",
        "  tag_series = df column with tags for each sentence.\n",
        "\n",
        "  Returns:\n",
        "    - dictionary mapping tags to indexes (label)\n",
        "    - dictionary mappign inedexes to tags\n",
        "    - The label corresponding to tag 'O'\n",
        "    - A set of unique tags ecountered in the trainind df, this will define the classifier dimension\n",
        "  \"\"\"\n",
        "\n",
        "  if not isinstance(tags_series, pd.Series):\n",
        "      raise TypeError('Input should be a padas Series')\n",
        "\n",
        "  unique_tags = set()\n",
        "  \n",
        "  for tag_list in df_train[\"tagged_text\"]:\n",
        "    for tag in tag_list.split():\n",
        "      unique_tags.add(tag)\n",
        "\n",
        "\n",
        "  tag2idx = {k:v for v,k in enumerate(sorted(unique_tags))}\n",
        "  idx2tag = {k:v for v,k in tag2idx.items()}\n",
        "\n",
        "  unseen_label = tag2idx[\"O\"]\n",
        "\n",
        "  return tag2idx, idx2tag, unseen_label, unique_tags"
      ],
      "metadata": {
        "id": "bpF4LnepCgXk"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def match_tokens_labels(tokenized_input, tags, ignore_token = -100):\n",
        "        '''\n",
        "        Used in the custom dataset.\n",
        "        -100 will be tha label used to match additional tokens like [CLS] [PAD] that we dont care about. \n",
        "\n",
        "        Inputs : \n",
        "          - tokenized_input : tokenizer over the imput text -> {input_ids, attention_mask}\n",
        "          - tags : is a single label array -> [O O O O O O O O O O O O O O B-tim O]\n",
        "        \n",
        "        Returns a list of labels that match the tokenized text -> [-100, 3,5,6,-100,...]\n",
        "        '''\n",
        "\n",
        "        #gives an array [ None , 0 , 1 ,2 ,... None]. Each index tells the word of reference of the token\n",
        "        word_ids = tokenized_input.word_ids()\n",
        "\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "\n",
        "        for word_idx in word_ids:\n",
        "\n",
        "            if word_idx is None:\n",
        "                label_ids.append(ignore_token)\n",
        "\n",
        "            #if its equal to the previous word we can add the same label id of the provious or -100 \n",
        "            else :\n",
        "                try:\n",
        "                  reference_tag = tags[word_idx]\n",
        "                  label_ids.append(tag2idx[reference_tag])\n",
        "                except:\n",
        "                  label_ids.append(ignore_token)\n",
        "              \n",
        "            \n",
        "            previous_word_idx = word_idx\n",
        "\n",
        "        return label_ids"
      ],
      "metadata": {
        "id": "kw75lLXMCgUv"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def freeze_model(model,num_layers = 1):\n",
        "  \"\"\"\n",
        "  Freeze last num_layers of a model to prevent ctastrophic forgetting.\n",
        "  Doesn't seem to work weel, its better to fine tune the entire netwok\n",
        "  \"\"\"\n",
        "  for id , params in enumerate(model.parameters()):\n",
        "    if id == len(list(model.parameters())) - num_layers: \n",
        "      print(\"last layer unfreezed\")\n",
        "      params.requires_grad = True\n",
        "    else:\n",
        "      params.requires_grad = False\n",
        "  return model"
      ],
      "metadata": {
        "id": "69qb3r3ICgR4"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(model, train_dataset, dev_dataset, optimizer,  batch_size, epochs):\n",
        "  \n",
        "  train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
        "  dev_dataloader = DataLoader(dev_dataset, batch_size = batch_size, shuffle = True)\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  model = model.to(device)\n",
        "\n",
        "  for epoch in range(epochs) : \n",
        "    \n",
        "    train_metrics = MetricsTracking()\n",
        "    total_loss_train = 0\n",
        "\n",
        "    model.train() #train mode\n",
        "\n",
        "    for train_data, train_label in tqdm(train_dataloader):\n",
        "\n",
        "      train_label = train_label.to(device)\n",
        "      '''\n",
        "      squeeze in order to match the sizes. From [batch,1,seq_len] --> [batch,seq_len] \n",
        "      '''\n",
        "      mask = train_data['attention_mask'].squeeze(1).to(device)\n",
        "      input_id = train_data['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      output = model(input_id, mask, train_label)\n",
        "      loss, logits = output.loss, output.logits\n",
        "      predictions = logits.argmax(dim= -1) \n",
        "\n",
        "      #compute metrics\n",
        "      train_metrics.update(predictions, train_label)\n",
        "      total_loss_train += loss.item()\n",
        "\n",
        "      #grad step\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    \n",
        "    '''\n",
        "    EVALUATION MODE\n",
        "    '''            \n",
        "    model.eval()\n",
        "\n",
        "    dev_metrics = MetricsTracking()\n",
        "    total_loss_dev = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      for dev_data, dev_label in dev_dataloader:\n",
        "\n",
        "        dev_label = dev_label.to(device)\n",
        "\n",
        "        mask = dev_data['attention_mask'].squeeze(1).to(device)\n",
        "        input_id = dev_data['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "        output = model(input_id, mask, dev_label)\n",
        "        loss, logits = output.loss, output.logits\n",
        "\n",
        "        predictions = logits.argmax(dim= -1)     \n",
        "\n",
        "        dev_metrics.update(predictions, dev_label)\n",
        "        total_loss_dev += loss.item()\n",
        "    \n",
        "    train_results = train_metrics.return_avg_metrics(len(train_dataloader))\n",
        "    dev_results = dev_metrics.return_avg_metrics(len(dev_dataloader))\n",
        "\n",
        "    print(f\"TRAIN \\nLoss: {total_loss_train / len(train_dataset)} \\nMetrics {train_results}\\n\" ) \n",
        "    print(f\"VALIDATION \\nLoss {total_loss_dev / len(dev_dataset)} \\nMetrics{dev_results}\\n\" )   "
      ],
      "metadata": {
        "id": "4cmgaFDZCgPA"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "_sWT8DmOIvGo",
        "outputId": "5620dc79-3731-492c-e5fc-97b0c7b9da8f"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 Clean1  \\\n",
              "3538  amp warpac nato not only provoke ukrainerussia...   \n",
              "2485  website contact forms to spread bazarloader ma...   \n",
              "2253  a number of captured ukrainian armor by dprrus...   \n",
              "3890  dont have any position in bitcoin or eth now y...   \n",
              "1847  downgraded their forecasts for us economic gro...   \n",
              "...                                                 ...   \n",
              "2646  just in russians are liquidating billions in b...   \n",
              "1799  bemil nft metaverse pe bemilgame i would very ...   \n",
              "1852  countries human beings are born free and equal...   \n",
              "2121   israel pm proposed zelenskyy to surrender to ...   \n",
              "1435  russia began massing troops on the ukraine bor...   \n",
              "\n",
              "                                            tagged_text  \n",
              "3538                  O O U-ORG O O O O O O O O O O O O  \n",
              "2485                  O O O O O O O O O O O B-ORG L-ORG  \n",
              "2253             O O O O O O O U-NORP O O O O U-GPE O O  \n",
              "3890  O O O O O O O O O O O O O O O B-DATE I-DATE L-...  \n",
              "1847          O O O O O O O O B-DATE L-DATE O O O O O O  \n",
              "...                                                 ...  \n",
              "2646  O O U-NORP O O U-CARDINAL O O O O O U-GPE O O ...  \n",
              "1799    U-ORG O O O O O O O O O O O O O O O O O O O O O  \n",
              "1852        O O O O O O O O O O O O O O O O O U-GPE O O  \n",
              "2121            O U-GPE O O O O O O U-GPE O O O O O O O  \n",
              "1435  U-GPE O O O O O O O B-DATE I-DATE I-DATE I-DAT...  \n",
              "\n",
              "[2405 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f7b9af56-def3-4f5a-b79e-3053fefba88c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Clean1</th>\n",
              "      <th>tagged_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3538</th>\n",
              "      <td>amp warpac nato not only provoke ukrainerussia...</td>\n",
              "      <td>O O U-ORG O O O O O O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2485</th>\n",
              "      <td>website contact forms to spread bazarloader ma...</td>\n",
              "      <td>O O O O O O O O O O O B-ORG L-ORG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2253</th>\n",
              "      <td>a number of captured ukrainian armor by dprrus...</td>\n",
              "      <td>O O O O O O O U-NORP O O O O U-GPE O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3890</th>\n",
              "      <td>dont have any position in bitcoin or eth now y...</td>\n",
              "      <td>O O O O O O O O O O O O O O O B-DATE I-DATE L-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1847</th>\n",
              "      <td>downgraded their forecasts for us economic gro...</td>\n",
              "      <td>O O O O O O O O B-DATE L-DATE O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2646</th>\n",
              "      <td>just in russians are liquidating billions in b...</td>\n",
              "      <td>O O U-NORP O O U-CARDINAL O O O O O U-GPE O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1799</th>\n",
              "      <td>bemil nft metaverse pe bemilgame i would very ...</td>\n",
              "      <td>U-ORG O O O O O O O O O O O O O O O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1852</th>\n",
              "      <td>countries human beings are born free and equal...</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O U-GPE O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2121</th>\n",
              "      <td>israel pm proposed zelenskyy to surrender to ...</td>\n",
              "      <td>O U-GPE O O O O O O U-GPE O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1435</th>\n",
              "      <td>russia began massing troops on the ukraine bor...</td>\n",
              "      <td>U-GPE O O O O O O O B-DATE I-DATE I-DATE I-DAT...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2405 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7b9af56-def3-4f5a-b79e-3053fefba88c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f7b9af56-def3-4f5a-b79e-3053fefba88c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f7b9af56-def3-4f5a-b79e-3053fefba88c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tag2idx, idx2tag , unseen_label, unique_tags = tags_mapping(df_train[\"tagged_text\"])\n",
        "\n",
        "#create the label column from tag. Unseen labels will be tagged as \"O\"\n",
        "for df in [df_train, df_dev, df_test]:\n",
        "  df2[\"labels\"] = df2[\"tagged_text\"].apply(lambda tags : tags_2_labels(tags, tag2idx))"
      ],
      "metadata": {
        "id": "4EZhfqd5CgMI"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = df_train[\"Clean1\"].values.tolist()\n",
        "\n",
        "#toeknized text\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "text_tokenized = tokenizer(text , padding = \"max_length\" , truncation = True, return_tensors = \"pt\" )\n",
        "\n",
        "#mapping token to original word\n",
        "word_ids = text_tokenized.word_ids()\n"
      ],
      "metadata": {
        "id": "abCK4lJQCgJE"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DistilbertNER(len(unique_tags))\n",
        "#Prevent Catastrofic Forgetting\n",
        "#model = freeze_model(model, num_layers = 2)\n",
        "\n",
        "#datasets\n",
        "train_dataset = NerDataset(df_train)\n",
        "dev_dataset = NerDataset(df_dev)\n",
        "\n",
        "lr = 1e-2\n",
        "optimizer = SGD(model.parameters(), lr=lr, momentum = 0.9)  \n",
        "\n",
        "\n",
        "#MAIN\n",
        "parameters = {\n",
        "    \"model\": model,\n",
        "    \"train_dataset\": train_dataset,\n",
        "    \"dev_dataset\" : dev_dataset,\n",
        "    \"optimizer\" : optimizer,\n",
        "    \"batch_size\" : 32,\n",
        "    \"epochs\" : 8\n",
        "}\n",
        "\n",
        "train_loop(**parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAuolfueGRlP",
        "outputId": "9f83fef7-f40e-4bbd-f4d4-57cf689d58bc"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForTokenClassification: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|██████████| 76/76 [01:47<00:00,  1.42s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN \n",
            "Loss: 0.03331713289827914 \n",
            "Metrics {'acc': 0.832, 'f1': 0.047, 'precision': 0.044, 'recall': 0.052}\n",
            "\n",
            "VALIDATION \n",
            "Loss 0.027712982360141938 \n",
            "Metrics{'acc': 0.849, 'f1': 0.048, 'precision': 0.045, 'recall': 0.052}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 76/76 [01:45<00:00,  1.39s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN \n",
            "Loss: 0.027002981621113736 \n",
            "Metrics {'acc': 0.849, 'f1': 0.049, 'precision': 0.045, 'recall': 0.053}\n",
            "\n",
            "VALIDATION \n",
            "Loss 0.025473860841778856 \n",
            "Metrics{'acc': 0.849, 'f1': 0.047, 'precision': 0.044, 'recall': 0.052}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 76/76 [01:45<00:00,  1.39s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN \n",
            "Loss: 0.02414424912597434 \n",
            "Metrics {'acc': 0.85, 'f1': 0.063, 'precision': 0.062, 'recall': 0.066}\n",
            "\n",
            "VALIDATION \n",
            "Loss 0.022402851856671846 \n",
            "Metrics{'acc': 0.852, 'f1': 0.061, 'precision': 0.075, 'recall': 0.061}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 76/76 [01:45<00:00,  1.39s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN \n",
            "Loss: 0.021091096763055685 \n",
            "Metrics {'acc': 0.858, 'f1': 0.088, 'precision': 0.098, 'recall': 0.091}\n",
            "\n",
            "VALIDATION \n",
            "Loss 0.018214177205508067 \n",
            "Metrics{'acc': 0.868, 'f1': 0.144, 'precision': 0.18, 'recall': 0.142}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 76/76 [01:45<00:00,  1.39s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN \n",
            "Loss: 0.01778093116694825 \n",
            "Metrics {'acc': 0.871, 'f1': 0.199, 'precision': 0.282, 'recall': 0.184}\n",
            "\n",
            "VALIDATION \n",
            "Loss 0.014988677541332285 \n",
            "Metrics{'acc': 0.889, 'f1': 0.297, 'precision': 0.373, 'recall': 0.286}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 76/76 [01:45<00:00,  1.39s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN \n",
            "Loss: 0.014630497406525325 \n",
            "Metrics {'acc': 0.889, 'f1': 0.313, 'precision': 0.405, 'recall': 0.292}\n",
            "\n",
            "VALIDATION \n",
            "Loss 0.011227592652404134 \n",
            "Metrics{'acc': 0.91, 'f1': 0.421, 'precision': 0.497, 'recall': 0.409}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 76/76 [01:45<00:00,  1.39s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN \n",
            "Loss: 0.011818867568662409 \n",
            "Metrics {'acc': 0.904, 'f1': 0.394, 'precision': 0.465, 'recall': 0.383}\n",
            "\n",
            "VALIDATION \n",
            "Loss 0.009404329153207632 \n",
            "Metrics{'acc': 0.916, 'f1': 0.449, 'precision': 0.544, 'recall': 0.419}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 76/76 [01:45<00:00,  1.39s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN \n",
            "Loss: 0.009793331847369299 \n",
            "Metrics {'acc': 0.918, 'f1': 0.472, 'precision': 0.54, 'recall': 0.462}\n",
            "\n",
            "VALIDATION \n",
            "Loss 0.0070780627754770545 \n",
            "Metrics{'acc': 0.936, 'f1': 0.528, 'precision': 0.568, 'recall': 0.542}\n",
            "\n"
          ]
        }
      ]
    }
  ]
}